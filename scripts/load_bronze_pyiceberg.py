# -*- coding: utf-8 -*-
"""
Load Bronze parquet files into Iceberg tables using PyIceberg REST Catalog
Run from: local_datalake directory with .venv activated

Riot API Configuration Documentation
=====================================
This script is part of the data ingestion pipeline for League of Legends data.
It loads parquet files generated by the Riot API extraction scripts into Iceberg tables.

Data Source:
- Parquet files in data/bronze/ directory, generated by extraction scripts:
  - data/extraction/01_ladder.py: Extracts challenger/grandmaster/master ladder data
  - data/extraction/02_match_ids.py: Extracts match IDs for players in ladder
  - data/extraction/03_matches.py: Extracts match details (participants, teams)

Configuration References:
- This script does NOT directly use Riot API keys
- Riot API configuration is managed in: data/extraction/config.py
  - RIOT_API_KEY: Loaded from environment variable
  - REGION, PLATFORM, QUEUE constants
- This script uses its own environment variables for Iceberg/MinIO:
  - ICEBERG_REST_URI: REST catalog endpoint (default: http://localhost:8181)
  - MINIO_ENDPOINT: S3-compatible storage (default: http://localhost:9000)
  - MINIO_ACCESS_KEY, MINIO_SECRET_KEY: MinIO credentials
  - ICEBERG_WAREHOUSE: S3 warehouse path (default: s3://lakehouse/warehouse)

Tables Loaded:
- bronze.ladder: Player rankings from Riot ladder API
- bronze.match_ids: Match IDs extracted for ladder players
- bronze.matches_participants: Individual player stats from matches
- bronze.matches_teams: Team-level stats from matches

Pipeline Flow:
1. Extraction scripts (01_*.py, 02_*.py, 03_*.py) call Riot API using config.py
2. Data is saved as parquet files in data/bronze/
3. This script loads parquet files into Iceberg tables
4. DBT transformations create silver/gold layers
"""

import logging
import os
from pathlib import Path
from typing import Any

import pyarrow as pa
import pyarrow.parquet as pq
from pyiceberg.catalog import Catalog, load_catalog
from pyiceberg.partitioning import PartitionSpec
from pyiceberg.schema import Schema
from pyiceberg.table import Table
from pyiceberg.table.sorting import SortOrder
from pyiceberg.types import (
    BooleanType,
    DoubleType,
    IntegerType,
    LongType,
    StringType,
    TimestampType,
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# Directory paths
BRONZE_DIR: Path = Path(__file__).parent.parent / "data" / "bronze"

# Environment variable configuration with defaults
ICEBERG_REST_URI: str = os.getenv("ICEBERG_REST_URI", "http://localhost:8181")
MINIO_ENDPOINT: str = os.getenv("MINIO_ENDPOINT", "http://localhost:9000")
MINIO_ACCESS_KEY: str = os.getenv("MINIO_ACCESS_KEY", "minioadmin")
MINIO_SECRET_KEY: str = os.getenv("MINIO_SECRET_KEY", "miniopassword123")
ICEBERG_WAREHOUSE: str = os.getenv("ICEBERG_WAREHOUSE", "s3://lakehouse/warehouse")


def get_catalog_config() -> dict[str, str]:
    """Build catalog configuration from environment variables.

    Returns:
        Dictionary containing catalog configuration parameters.
    """
    return {
        "type": "rest",
        "uri": ICEBERG_REST_URI,
        "s3.endpoint": MINIO_ENDPOINT,
        "s3.access-key-id": MINIO_ACCESS_KEY,
        "s3.secret-access-key": MINIO_SECRET_KEY,
        "warehouse": ICEBERG_WAREHOUSE,
    }


def connect_to_catalog() -> Catalog:
    """Connect to the Iceberg REST catalog.

    Returns:
        Connected Iceberg catalog instance.
    """
    config = get_catalog_config()
    catalog = load_catalog("iceberg", **config)
    logger.info("Connected to Iceberg REST catalog at %s", ICEBERG_REST_URI)
    return catalog


def ensure_namespace_exists(catalog: Catalog, namespace: str) -> None:
    """Create namespace if it doesn't exist.

    Args:
        catalog: The Iceberg catalog instance.
        namespace: Name of the namespace to create.
    """
    try:
        catalog.create_namespace(namespace)
        logger.info("Created namespace: %s", namespace)
    except Exception as e:
        if "already exists" in str(e).lower() or "AlreadyExistsException" in str(e):
            logger.info("Namespace %s already exists", namespace)
        else:
            logger.warning("Namespace error: %s", e)


def get_tables_config() -> dict[str, Path]:
    """Get configuration for tables to load.

    Returns:
        Dictionary mapping table names to their parquet file paths.
    """
    return {
        "ladder": BRONZE_DIR / "ladder.parquet",
        "match_ids": BRONZE_DIR / "match_ids.parquet",
        "matches_participants": BRONZE_DIR / "matches_participants.parquet",
        "matches_teams": BRONZE_DIR / "matches_teams.parquet",
    }


def load_parquet_file(parquet_path: Path) -> pa.Table | None:
    """Load a parquet file into a PyArrow table.

    Args:
        parquet_path: Path to the parquet file.

    Returns:
        PyArrow table if successful, None if file not found.
    """
    if not parquet_path.exists():
        logger.warning("File not found: %s", parquet_path)
        return None

    arrow_table = pq.read_table(parquet_path)
    logger.info(
        "Read %d rows, %d columns from %s",
        arrow_table.num_rows,
        len(arrow_table.column_names),
        parquet_path.name,
    )
    logger.debug("Columns: %s", arrow_table.column_names)
    return arrow_table


def drop_table_if_exists(catalog: Catalog, full_table_name: str) -> None:
    """Drop a table if it exists.

    Args:
        catalog: The Iceberg catalog instance.
        full_table_name: Fully qualified table name (namespace.table).
    """
    try:
        catalog.drop_table(full_table_name)
        logger.info("Dropped existing table: %s", full_table_name)
    except Exception:
        pass  # Table doesn't exist


def create_and_load_table(
    catalog: Catalog,
    full_table_name: str,
    arrow_table: pa.Table,
) -> bool:
    """Create an Iceberg table and load data into it.

    Args:
        catalog: The Iceberg catalog instance.
        full_table_name: Fully qualified table name (namespace.table).
        arrow_table: PyArrow table containing the data to load.

    Returns:
        True if successful, False otherwise.
    """
    try:
        iceberg_table: Table = catalog.create_table(
            identifier=full_table_name,
            schema=arrow_table.schema,
        )
        logger.info("Created table: %s", full_table_name)

        iceberg_table.append(arrow_table)
        logger.info("Loaded %d rows into %s", arrow_table.num_rows, full_table_name)
        return True

    except Exception as e:
        logger.error("Failed to create/load table %s: %s", full_table_name, e)
        return False


def process_table(
    catalog: Catalog,
    table_name: str,
    parquet_path: Path,
    namespace: str = "bronze",
) -> bool:
    """Process a single table: load from parquet and insert into Iceberg.

    Args:
        catalog: The Iceberg catalog instance.
        table_name: Name of the table.
        parquet_path: Path to the parquet file.
        namespace: Iceberg namespace (default: bronze).

    Returns:
        True if successful, False otherwise.
    """
    logger.info("Processing: %s", table_name)

    arrow_table = load_parquet_file(parquet_path)
    if arrow_table is None:
        return False

    full_table_name = f"{namespace}.{table_name}"

    drop_table_if_exists(catalog, full_table_name)
    return create_and_load_table(catalog, full_table_name, arrow_table)


def verify_tables(
    catalog: Catalog, table_names: list[str], namespace: str = "bronze"
) -> None:
    """Verify that tables were loaded correctly.

    Args:
        catalog: The Iceberg catalog instance.
        table_names: List of table names to verify.
        namespace: Iceberg namespace (default: bronze).
    """
    logger.info("=" * 60)
    logger.info("VERIFICATION")
    logger.info("=" * 60)

    for table_name in table_names:
        full_table_name = f"{namespace}.{table_name}"
        try:
            tbl: Table = catalog.load_table(full_table_name)
            scan = tbl.scan()
            arrow_data = scan.to_arrow()
            logger.info("%s: %d rows", full_table_name, len(arrow_data))
        except Exception as e:
            logger.error("%s: ERROR - %s", full_table_name, e)


def main() -> None:
    """Main entry point for loading Bronze data to Iceberg."""
    logger.info("=" * 60)
    logger.info("Loading Bronze data to Iceberg via PyIceberg REST Catalog")
    logger.info("=" * 60)

    # Connect to Iceberg REST catalog
    catalog = connect_to_catalog()

    # Create bronze namespace if not exists
    ensure_namespace_exists(catalog, "bronze")

    # Tables to load
    tables = get_tables_config()

    # Process each table
    for table_name, parquet_path in tables.items():
        process_table(catalog, table_name, parquet_path)

    # Verify
    verify_tables(catalog, list(tables.keys()))

    logger.info("Done! Now run: dbt run")


if __name__ == "__main__":
    main()
